{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Tweet Sentiment with Word Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is from:\n",
    "\n",
    "https://www.kaggle.com/kazanova/sentiment140/downloads/sentiment140.zip/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get directory path\n",
    "import os\n",
    "os.getcwd( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change directory\n",
    "os.chdir('/Users/Yrelav/Documents/Cognizant/Training/Gen_C_Instruction/NLP') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785642, 6)\n",
      "Index(['label', 'id', 'ds', 'flag', 'user', 'tweet'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label     int64\n",
       "id        int64\n",
       "ds       object\n",
       "flag     object\n",
       "user     object\n",
       "tweet    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "#Read in the data\n",
    "columns = ['label', 'id', 'ds', 'flag', 'user', 'tweet']\n",
    "df = pd.read_csv('Tweets_sentiment1.csv', names=columns)\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the structure of the tweet column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>id</th>\n",
       "      <th>ds</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>785637</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785638</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785639</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785640</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785641</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        label          id                            ds      flag  \\\n",
       "785637      4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "785638      4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "785639      4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "785640      4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "785641      4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                              tweet  \n",
       "785637  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "785638      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "785639           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "785640     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "785641   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    2731\n",
       "0.0    1458\n",
       "Name: label_pred, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create some missing values to predict\n",
    "df['label_pred'] = df.apply(lambda _: '', axis=1)\n",
    "\n",
    "df['label_pred'] = np.where((df['ds'].str.contains('Jun 06 15')) & (df['label'] == 0) , 0,np.nan)\n",
    "df.loc[(df['ds'].str.contains('Jun 03 05')) & (df['label'] == 4), 'label_pred'] = 4\n",
    "\n",
    "\n",
    "df['label_pred'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that our new column, 'label_pred', only has a few thousand labeled values. This is much more likely if humans hand-label the data. Techniques are being developed to automatically label data, but most datasets will be human labeled. Getting good training sets is the challenge for machine learning. Bigger is better! But really big training sets take a lot of memory to process and visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tweets contain urls amd @ statements, let's check how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368546,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2     @starbucksapron got my &quot;friend&quot; visi...\n",
       "3     @princessjoya The place you used to work with ...\n",
       "4     @missemilymac AHHHHH!!!!  That sucks! So, are ...\n",
       "6                                       @gimp01 me too \n",
       "10    @MizzBizznizz ah shit don't tell me that I'm o...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_co = df['tweet'].loc[df['tweet'].str.contains(\"@\")]\n",
    "print(df_co.shape)\n",
    "df_co.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More than 35,000 of the tweets have urls in them. I will need to remove these during preprocessing, along with @statements.\n",
    "\n",
    "### Create a sparse matrix for positive, negative, and neutral labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Define a function to clean the text\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    \n",
    "    # <write a regex expression to take out the @ and what follows>\n",
    "    # <write a regex expression to take out the web links (http) and what follows>\n",
    "    \n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    text = re.sub(r\"co\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text\n",
    "\n",
    "#Clean the text\n",
    "df['tweet'] = df['tweet'].map(lambda com : clean_text(com))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is a lambda function?\n",
    "\n",
    "https://www.python-course.eu/lambda.php\n",
    "\n",
    "#### Example\n",
    "\n",
    "r = map(func, seq)\n",
    "\n",
    "The first argument func is the name of a function and the second a sequence (e.g. a list) seq. map() applies the function func to all the elements of the sequence seq. It returns a new list with the elements changed by func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This let's us count how many 'http' are left: There should be about 35,000\n",
    "df_clean = df['tweet'].loc[df['tweet'].str.contains('http')]\n",
    "print(df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This let's us count how many are left: There should be zero.\n",
    "df_clean = df['tweet'].loc[df['tweet'].str.contains('@')]\n",
    "print(df_clean.shape)\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a table to examine the distribution of tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the shape of the training set (should be 4189, 7)\n",
    "df_train = df[df['label_pred'].notnull()]\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check distribution of words in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a histogram to see the distribution of the words in the tweets\n",
    "\n",
    "lens = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Featurize the data\n",
    "\n",
    "https://machinelearningmastery.com/prepare-text-data-machine-learning-scikit-learn/\n",
    "\n",
    "Here we are using CountVectorizer so that we can make the cumulative distribution function below. This is NOT the same as featurizing before running classification algorithms. Follow the example from the ARticles notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variables (features) from the tweets text.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "cv_fit=cv.fit_transform(df_train['tweet'])\n",
    "\n",
    "cv_fit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data\n",
    "\n",
    "#### Use a cumulative distribution function to determine the minimum and maximum words needed to capture the variation in the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = cv_fit.toarray()\n",
    "words = words.astype(dtype=bool)\n",
    "numlist = [0]*len(words[0])\n",
    "for word in words:\n",
    "    numlist += word\n",
    "print(numlist[1:10])\n",
    "type(numlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    # Number of data points: n\n",
    "    n = len(data)\n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n + 1) / n\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ECDF \n",
    "x, y = ecdf(numlist)\n",
    "\n",
    "# Generate plot\n",
    "_ = plt.plot(x, y, marker='.', linestyle='none')\n",
    "plt.rcParams[\"figure.figsize\"] = [10,5]\n",
    "\n",
    "# Label the axes\n",
    "_ = plt.xlim(0,100)\n",
    "_ = plt.xticks(np.arange(0, 100, step=5))\n",
    "_ = plt.xlabel('Number of Documents')\n",
    "_ = plt.ylabel('Percentage of Words Appearing')\n",
    "plt.savefig('ecdf_tweets.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure 1. ECDF for tweets in the corpus.\n",
    "\n",
    "This graph shows that most of words are found within the first 25 tweets. We can set the df_min = 1 and the df_max = 15\n",
    "\n",
    "## Visualize with a word cloud all of the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with loading all necessary libraries\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make text for all tweets\n",
    "text = list(df_train['tweet'].values)\n",
    "\n",
    "summary1 = []\n",
    "for i in range(len(text)):\n",
    "    summary = ' '.join(str(x) for x in text)\n",
    "    summary1.append(summary) \n",
    "alltext = summary1[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image:\n",
    "wordcloud = WordCloud().generate(alltext)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "# Save the image in the img folder:\n",
    "#wordcloud.to_file('/Users/valery/Documents/Springboard/Capstone 2/racecloud.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 2. Word cloud for all the tweets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualize with word clouds for each category: Positive, Negative, Neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make text for each category tweets\n",
    "df_pos = df_train[df_train['label_pred'] == 4]\n",
    "df_neg = df_train[df_train['label_pred'] == 0]\n",
    "\n",
    "text_pos = list(df_pos['tweet'].values)\n",
    "text_neg = list(df_neg['tweet'].values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Positive tweets\n",
    "\n",
    "<add code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Negative tweets\n",
    " \n",
    "<add code here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image for positive tweets:\n",
    "wordcloud = WordCloud().generate(alltext_pos)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "# Save the image in the img folder:\n",
    "#wordcloud.to_file('/Users/valery/Documents/Springboard/Capstone 2/racecloud_pos.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 3. Word cloud for positive tweets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and generate a word cloud image for negative tweets:\n",
    "\n",
    "<add code here>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fig 4. Word cloud for negative tweets.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are you thoughts on these tweets? Do you think the automatic labeling worked well to distinquish the difference between positive and negative tweets?\n",
    "\n",
    "## Mini-Project Assignment for Tuesday\n",
    "\n",
    "1. Create a sparse matrix (one-hot encoder/vector) for the training set for Positive and Negative categories. Remember that positive tweets are tagged with 4 and negative tweets are tagged with 0. \n",
    "\n",
    "2. Set up the vectorizer/featurizer and adapt the code to featurize the tweets.\n",
    "3. Pick one of the classifiers we used for the articles Monday morning and run it with this data. \n",
    "\n",
    "Do what you can, struggle a little, and we'll talk about it Tuesday morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
